{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ff8b3b",
   "metadata": {},
   "source": [
    "- Sentiment analysis around the top bigram/trigram related to tools referenced on Twitter. \n",
    "\t- Topics within positive vs. negative, 2020 vs. 2021\n",
    "\t- Topics models for different tools, 2020 vs. 2021\n",
    "\n",
    "- Removing search words\n",
    "\t- Remove bottom N% - justify based on past research\n",
    "\t- Check where the search terms land in terms of relative rankings for where search terms occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457a14a",
   "metadata": {},
   "source": [
    "## Packages and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6166c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "# For topic modeling\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352bcdf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('TWITTER_HANDLE')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def model_check(df_corpus, df_dict, num_topics):\n",
    "    # Build model\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=df_corpus, \n",
    "                                                id2word=df_dict, \n",
    "                                                num_topics=num_topics, \n",
    "                                                random_state=100,\n",
    "                                                update_every=1, \n",
    "                                                chunksize=1000, \n",
    "                                                passes=10, \n",
    "                                                alpha='auto', \n",
    "                                                per_word_topics=True)\n",
    "    # Compute complexity and coherence score\n",
    "    complexity = lda_model.log_perplexity(data)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=data, \n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    return complexity, coherence\n",
    "\n",
    "def topic_check(df, text_col):\n",
    "    # Create specific corpus from passed df\n",
    "    df_text = []\n",
    "    for i in range(len(df_text)):\n",
    "        tokens = prepare_text_for_lda(df_text[text_col][i])\n",
    "        df_text.append(tokens)\n",
    "\n",
    "    df_dict = corpora.Dictionary(df_text)\n",
    "    df_corpus = [dictionary.doc2bow(text) for text in df_text]\n",
    "\n",
    "    # Create model and save\n",
    "    topics = []\n",
    "    complexity = []\n",
    "    coherence = []\n",
    "    for i in range(1, 20):\n",
    "        cmplx, coh = model_check(df_corpus=df_corpus,\n",
    "                                 df_dict=df_dict, \n",
    "                                 num_topics=i)\n",
    "        topics.append(i)\n",
    "        complexity.append(cmplx)\n",
    "        coherence.append(coh)\n",
    "\n",
    "    # Save as a df\n",
    "    df_df = pd.DataFrame({'topics': topics, \n",
    "                          'complexity':complexity, \n",
    "                          'coherence':coherence})\n",
    "    return df_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa592575",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6288a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "raw_data = pd.read_csv('../data/03_primary/all_data.csv')\n",
    "data = raw_data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2efc17",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data for topic modeling\n",
    "import random\n",
    "text_data = []\n",
    "for i in range(len(data)):\n",
    "    tokens = prepare_text_for_lda(data['content'][i])\n",
    "    text_data.append(tokens)\n",
    "    if random.random()>0.95:\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999cd3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the cols we need\n",
    "df = pd.DataFrame({'tweet':text_data, \n",
    "                   'sentiment':data['vader_com'], \n",
    "                   'year':data['year']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936791e6",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the cols are numeric\n",
    "df['sentiment'] = df['sentiment'].astype(float)\n",
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e13a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive vs. negative, 2020 vs. 2021\n",
    "pos_20 = df[(df['year']==2020) & (df['sentiment']>=0.5)].reset_index(drop=True)\n",
    "pos_21 = df[(df['year']==2021) & (df['sentiment']>=0.5)].reset_index(drop=True)\n",
    "neg_20 = df[(df['year']==2020) & (df['sentiment']<=-0.5)].reset_index(drop=True)\n",
    "neg_21 = df[(df['year']==2021) & (df['sentiment']<=-0.5)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join tweets together\n",
    "l_str_p20 = ','.join(list(pos_20['tweet'].values))\n",
    "l_str_p21 = ','.join(list(pos_21['tweet'].values))\n",
    "l_str_n20 = ','.join(list(neg_20['tweet'].values))\n",
    "l_str_n21 = ','.join(list(neg_21['tweet'].values))\n",
    "\n",
    "# Create wordcloud objects\n",
    "for item in [l_str_p20, l_str_p21, l_str_n20, l_str_n21]:\n",
    "    wordcloud = WordCloud(background_color='white', max_words=2000, \n",
    "                      contour_width=3, contour_color='steelblue')\n",
    "    wordcloud.generate(item)\n",
    "    wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3091b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e629f342",
   "metadata": {},
   "source": [
    "## LDA with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('../data/04_intermediate/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07291b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire corpus\n",
    "topics = []\n",
    "complexity = []\n",
    "coherence = []\n",
    "for i in range(2, 20):\n",
    "    cmplx, coh = model_check(data=corpus, num_topics=i)\n",
    "    topics.append(i)\n",
    "    complexity.append(cmplx)\n",
    "    coherence.append(coh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477de659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a df\n",
    "corpus_topics = pd.DataFrame({'topics': topics, \n",
    "                             'complexity':complexity, \n",
    "                             'coherence':coherence})\n",
    "corpus_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Tweets from 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823be56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f89e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9a303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f4528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52c8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4dca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92439fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a853b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5871d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d757e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a7459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2fa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de834772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56714b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1c3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
